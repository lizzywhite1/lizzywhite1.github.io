---
title: 'A deep dive into Linear Regression'
date: 2025-07-13
permalink: /posts/2025/07/linear-regression/
tags:
  - regression
  - basics
---
# Motivation
Brilliant another blog post on linear regression, how creative (*eye roll*). Why would I make this post (I hear no one ask)? 
Well having dabbled in a few ML/Statistics projects, I have begun to realise how important it is to have a very 
**strong foundational understanding** of core concepts, before trying to undertake more complex ones. 
So I put my ego and my desire to dive into all the flashy ML models aside, and went to the first chapter of any book on statistical learning. 
Linear regression.  

I tasked myself with the challenge of building a linear regression model from scratch in Python (no scipy allowed!). 
"*This will be easy*" I thought. But as I started to read more into 
Linear Regression and began to build out the model, I realised how shallow my knowledge of Linear Regression actually was. 

In this post I will take you along my journey to "*re-learning*" linear regression from scratch. I hope to present it in a 
way that may be different to how you were taught it at university (or at least how I was), and detail my intial pitfalls 
when attempting to build out my own mock Scipy linregress function. 

# Theory
The aim of this section is to give a succinct overview of everything (I beleive) a student, like myself, should know about 
linear regression. This is not a textbook; if you want to dive deeper, I reccommend checking out the resources at the end.
## What even is (linear) regression?
If I had to sum up linear regression in one sentence, I'd say this. 

> Linear regression encapsulates a class of functions to model the relationship between inputs and quantitative targets using a linear
> combination of fixed basis functions of the input. 

So what does all of this mean? 

When we talk about regression in the world of statistics, we are simply referring to a type of prediction task in which 
we are interested in predicting a quantitive value (this could be a scalar or a vector; for simplicity we will assume it is a scalar), given a set of inputs. 
The "*linear*" in linear regression, simply means our prediction model is a linear function of the parameters, 
however **there is no requirement that we are linear with respect to our input vector**, $\textbf{x}$. More formally, we 
express these models in the form $$f(\textbf{x};\textbf{w})=w_0+\sum ^{M-1} _{i=1} w_i \phi_i (\textbf{x})\tag{1}$$where
- $\textbf{x}=(x_1,...x_D)$ is our $D-$dimensional input vector containing the features in which the model learns to predict 
the target (or output).
- $\textbf{w}=(w_0,...,w_M)$ is our $M-$ dimensional vector containing the model weights/parameters which are learnt to minimise 
some *error function* ie. the weights which help us minimise the distance between a true and predicted output.
- $\phi_i(\textbf{x})$ are our linear (or non-linear) basis functions of $\textbf{x}$. The span of these basis functions
makes up the finite dimensional subspace in which $f$ lives. 

A more compact way of expressing this, letting $\phi_0(\textbf{x})=1$ is
$$f(\textbf{x};\textbf{w})=\textbf{w}^T\mathbf{\phi}(\textbf{x})$$

This may seem foreign if youâ€™ve only ever encountered the standard linear regression model, which is written as$$
f(\mathbf{x}; \mathbf{w}) = w_0 + \sum_{i=1}^{M-1} w_i x_i. \tag{2}
$$

However, this is equivalent to Equation (1) when our basis functions are simply the **linear basis functions** 
$\phi_j(\mathbf{x}) = x_j$. However, by extending this class of functions by using non-linear basis functions 
we can model more complex relationships between the inputs and the target variable. These basis functions could be polynomials,
trigometric functions, interactions between features or a numeric coding of qualitative inputs.

## Probabilistic Interpretation of Linear Regression 


## How do these models "learn": Maximum Likelihood and Least Squares Approach
- Error functions
## Geometric Interpretation



# Building our Linear Regression Model
## Numerical Resolution 

## Implementing In Practise 

# Further Reading / Referneces 
